{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.ar_model import AutoReg, ar_select_order\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Set the figure size to (14,6)\n",
    "plt.rcParams['figure.figsize'] = (14,6)\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warmup\n",
    "\n",
    "## 1) Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a just an example time series\n",
    "\n",
    "df = pd.read_csv('arma_process.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Plot the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()\n",
    "plt.title('Remainder')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is this data stationary ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the augmented Dicky-Fuller stationarity test\n",
    "\n",
    "# recap: The null hypothesis is that the time series is NOT-stationary\n",
    "# i.e. a small p value, less than 0.05, means that you have a stationary series\n",
    "\n",
    "def print_adf(data):\n",
    "    \"\"\" \n",
    "    Prints the results of the augmented Dickey Fuller Test\n",
    "    \"\"\"\n",
    "    adf_stats, p, used_lag, n_obs, levels, information_criterion = adfuller(data)\n",
    "    \n",
    "    print(f\"\"\" \n",
    "              adf_stats: {adf_stats}\n",
    "              p: {p} \n",
    "              used lag: {used_lag} \n",
    "              number of observations: {n_obs}\n",
    "            \n",
    "              CI 99%: {levels['1%']}\n",
    "              CI 95%: {levels['5%']}\n",
    "              CI 90%: {levels['10%']}\n",
    "              information criterion (AIC): {information_criterion}\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_adf(df['remainder'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We then conclude from the results of the adf test that the time series we have is stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Inspect the Partial Autocorrelation (Box-Jenkins-Methodology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the partial autocorrelation function\n",
    "plot_pacf(df['remainder']);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for later: plot autocorrelation function\n",
    "\n",
    "#plot_acf(df['remainder']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: Inspecting the pacf plot we choose to include ? lags into our model ? How can we be additionally sure ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ar_select_order - brute force method that tries different models and takes the best one\n",
    "\n",
    "order = ar_select_order(df, maxlag=20, old_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many lags does ar_select_order suggest?\n",
    "\n",
    "order.ar_lags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Build a AR model with the right number of lags\n",
    "\n",
    "Everything points us towards using 4 lags for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a statsmodels AutoReg model\n",
    "# pure autoregressive model: AR4\n",
    "ar_model = AutoReg(df['remainder'], lags=4, old_names=False).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['remainder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the prediction\n",
    "\n",
    "df['remainder'].plot()\n",
    "plt.plot(ar_model.predict(), label='ar_predictions') # insample prediction\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looks good, can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA - Autoregressive Integrated Moving Average\n",
    "\n",
    "With the AR model we found a quite decent model for our data. The question is, can we do even better? \n",
    "\n",
    "One way we might be able to improve our model is by including a **Moving Average part (MA)** into the model, if it exists\n",
    "\n",
    "Simply speaking the **MA** part is just a different way of modeling time dependence. Instead of using past values of the variable itself we will **use past prediction errors to predict the future**. Mathematically this looks like:\n",
    "\n",
    "### 1) AR(p)\n",
    "\n",
    "The $AR(p)$ part is just an autoregressive part of the model where *p* denotes the number of lags to include.\n",
    "\n",
    "### 2) I(d)\n",
    "\n",
    "The $I(d)$ part is just the part where the model is detrended. *d* determines which order of differencing should be applied to the original time series data before modelling the AR and MA parts\n",
    "\n",
    "If the data is stationary, then $d = 0$\n",
    "\n",
    "### 3) MA(q)\n",
    "\n",
    "This is the new part that we have not seen before. Instead of regressing on past lags, the Moving Average approach regresses on past errors:\n",
    "\n",
    "**MA(1):** $\\hat{y_{t+1}} = b + \\phi*\\epsilon_{t}$\n",
    "\n",
    "where $\\epsilon_{t} = \\hat{y_{t}} - y_{t} $\n",
    "\n",
    "or adding more features (lags):\n",
    "\n",
    "**MA(2):** $\\hat{y_{t+1}} = b + \\phi_1*\\epsilon_{t} + \\phi_2*\\epsilon_{t-1}$\n",
    "\n",
    "or adding more features (lags):\n",
    "\n",
    "**MA(q):** $\\hat{y_{t+1}} = b + \\phi_1*\\epsilon_{t} + ... + \\phi_q*\\epsilon_{t-q-1}$\n",
    "\n",
    "\n",
    "### How do we determine the order of the MA term q?\n",
    "\n",
    "Instead of looking at the partial autocorrelation as was the case for the AR model we can look at the autocorrelation between observations $y_t$ and $y_{t-h}$.\n",
    "\n",
    "$$\n",
    "Corr(y_t, y_{t-h}) = \\frac{Cov(y_t, y_{t-h})}{\\sqrt{V(y_t)*V(y_{t-h})}}\n",
    "$$\n",
    "\n",
    "**What does the Box-Jenkins method say here?**\n",
    "\n",
    "#### Value of q\n",
    "\n",
    "The value of q is found from the autocorrelations plot as follows:\n",
    "\n",
    "\n",
    "- If the autocorrelations cut off after a few lags, the last lag with a large value would be the estimated value of q\n",
    "- If the autocorrelations do not cut off, but rather decay gradually, you either have an autoregressive model (q=0) or an ARIMA model with a positive p and q\n",
    "\n",
    "[source](https://www.ncss.com/wp-content/themes/ncss/pdf/Procedures/NCSS/The_Box-Jenkins_Method.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's examine both plots now\n",
    "\n",
    "plot_pacf(df['remainder']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(df['remainder']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogous to the plot of the partial autocorrelation for the AR part of the model, the plot of the autocorrelation function gives us an idea which lag to chose for the MA. If there is no clear cutoff this could mean\n",
    "\n",
    "- That the time series is better modelled by a pure AR model\n",
    "- That the time series is best modelled by a model including AR and MA terms (ARIMA)\n",
    "\n",
    "### How to read the ACF-plot and the PACF-plot\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "- If the ACF-Plot is showing an exponential and slow decay, and the PACF-Plot shows a drop after a certain lag, we conclude that the data is best modelled by an AR(p) process. p is given by the last meaningful lag in the PACF-Plot.\n",
    "\n",
    "### **AR process**\n",
    "\n",
    "ACF-Plot AR(1)             |  PACF-Plot AR(1)\n",
    ":-------------------------:|:-------------------------:\n",
    "![](./images/acf_ar.png)   |  ![](./images/pacf_ar.png)\n",
    "\n",
    "- If the ACF-Plot is showing a drop after a certain lag, and the PACF-Plot shows an exponential and slow decay, we conclude that the data is best modelled by an MA(q) process. q is given by the last meaningful lag in the ACF-Plot.\n",
    "\n",
    "---\n",
    "\n",
    "### **MA process**\n",
    "\n",
    "ACF-Plot MA(1)             |  PACF-Plot MA(1)\n",
    ":-------------------------:|:-------------------------:\n",
    "![](./images/acf_ma.png)   |  ![](./images/pacf_ma.png)\n",
    "\n",
    "- If both the ACF-Plot and the PACF-Plot are showing an exponential and slow decay, we conclude that the data is best modelled by an ARIMA(p,d,q) process. p and q cannot be inferred from the plots. Usually you would use an iterrative approach and try different combinations to find the best model. (eg. https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.auto_arima.html)\n",
    "\n",
    "---\n",
    "\n",
    "### **ARIMA process**\n",
    "\n",
    "ACF-Plot ARIMA(1,0,1)      |  PACF-Plot ARIMA(1,0,1)\n",
    ":-------------------------:|:-------------------------:\n",
    "![](./images/acf_arima.png)|  ![](./images/pacf_arima.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I determine which model to choose?\n",
    "\n",
    "\n",
    "1. test stationarity\n",
    "2. plot pacf and acf\n",
    "3. determine possible ranges for p and q values\n",
    "4. Fit all possible combinations (p,0,q) models and compare them. \n",
    "   Models with lower AIC/BIC score are better at explaining the data we have\n",
    "    \n",
    "\n",
    "#### What do AIC and BIC mean ? https://www.youtube.com/watch?v=McEN54l3EPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other option: brute force; run multiple models with several combinations of p and q and choose the best one where best is usuall measured in terms of AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima.arima import auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA(p,d,q)\n",
    "\n",
    "# p = number of AR lags\n",
    "# q = number of MA lags\n",
    "# d = the order of integration (if the data is stationary, d=0)\n",
    "\n",
    "auto_arima_model = auto_arima(df['remainder'], start_p=0, start_q=0, \n",
    "                              max_p=15, max_q=15, d=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated(I)\n",
    "\n",
    "Integrating a time series is an alternative way to model a trend of the time series.\n",
    "\n",
    "if $y_t$ is our time series and it has a trend component, then to de-trend the series and make it stationary, we can difference it ==> $y_t - y_{t-1}$ would be the time series differentiated by order 1\n",
    "\n",
    "Then to be able to get $y_t$ from the stationary de-trended series, we would need to **integrate** once, i.e. $I(1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i = pd.DataFrame({'y': range(101)})\n",
    "df_i.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i.shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first order differentiate this time series data\n",
    "df_i['y_diff'] = df_i.y - df_i.y.shift(1) # y_t - y_{t-1}\n",
    "df_i['y_difference'] = df_i['y'].diff()\n",
    "df_i.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to integrate the knowledge into the project ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# flights_train = pd.read_csv('flights_train.csv', parse_dates=True, index_col=0)\n",
    "flights_train = pd.read_csv(PATH + 'climate_train.csv', index_col = 0, parse_dates = True)\n",
    "\n",
    "flights_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1: inspect the time series by plotting\n",
    "\n",
    "- does the series have a trend ?\n",
    "- does the series have seasonality ?\n",
    "- is the series stationary ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flights_train.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_train.loc['1950':'1952'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### we can already see that there is trend and seasonality in the series, meaning it is non-stationary\n",
    "\n",
    "test_result=adfuller(flights_train['passengers'])\n",
    "\n",
    "print('ADF Statistic: %f' % test_result[0])\n",
    "print('p-value: %f' % test_result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ho - null hypothesis: series is non stationary\n",
    "#H1 - alternative hypothesis: series is stationary\n",
    "\n",
    "def adfuller_test(series):\n",
    "    result=adfuller(series)\n",
    "    labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n",
    "    for value,label in zip(result,labels):\n",
    "        print(label+' : '+str(value) )\n",
    "    if result[1] <= 0.05:\n",
    "        print(\"strong evidence against the null hypothesis(Ho), reject the null hypothesis. Data is stationary\")\n",
    "    else:\n",
    "        print(\"weak evidence against null hypothesis, indicating data is non-stationary\")\n",
    "\n",
    "        \n",
    "adfuller_test(flights_train['passengers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Make time series stationary\n",
    "\n",
    "why ?? this enables us to find the right model order (p,d,q) for our series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what to do if the time seris has a trend ?\n",
    "\n",
    "flights_train['diff1'] = flights_train['passengers'].diff(1)\n",
    "\n",
    "flights_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the differenced signal and inspect results of adfuller test\n",
    "\n",
    "flights_train['diff1'].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller_test(flights_train['diff1'].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### up till here, we can say that d = 1 and for now ignore the seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note 1: Even though the adfuller test p-value is less than 0.05, it is very close to that value. In this case, the reason is that there is seasonality in the time series that we did not yet extract. We will circle back to this in Seasonal ARIMA (SARIMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note 2: We should use the stationary version of the time series to plot ACF and PACF!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspecting the period of seasonality in the data\n",
    "\n",
    "flights_train['passengers'].loc['1950':'1952'].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**conclusion: there is a period of 12 (12 months of the year) after which the series have the same shape**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What to do is the series has seasonality ??\n",
    "\n",
    "\n",
    "## period m=12 is the period of my seasonality\n",
    "\n",
    "flights_train['seasonal_diff1'] = flights_train['diff1'].diff(12)\n",
    "\n",
    "flights_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first seasonal difference \n",
    "\n",
    "flights_train['seasonal_diff1'].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check results of adfuller test\n",
    "\n",
    "adfuller_test(flights_train['seasonal_diff1'].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3: Let's look at the acf and pacf plots (of the stationary differenced data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A: checking only the detrended data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(flights_train['diff1'].dropna());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(flights_train['diff1'].dropna());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### checking the seasonal differenced series (trend and seasonality both taken out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(flights_train['seasonal_diff1'].dropna());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(flights_train['seasonal_diff1'].dropna());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 4: Attempt multiple models and choose the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we will ignore the seasonality now and go with an ARIMA model that does not take seasonality in consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima_model = auto_arima(flights_train['passengers'], \n",
    "                              start_p=0, start_q=0, \n",
    "                              max_p=15, max_q=15, max_d=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and ARIMA (3,1,4) model (p,d,q)\n",
    "\n",
    "model = ARIMA(flights_train['passengers'], order=(3,1,4)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(flights_train['passengers'], label='passenger_data')\n",
    "plt.plot(model.predict(), label='arima_predictions')  # this is called in-sample predictions, predictions on test data\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate rmse on training data\n",
    "\n",
    "rmse_no_seasonality = np.sqrt(mean_squared_error(flights_train['passengers'], model.predict()))\n",
    "\n",
    "rmse_no_seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## so how can we check model behavior on unseen data ? How can we use the model to forecast ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) One step out-of-sample prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forecast()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Multiple steps out-of-sample predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(start='1960-01-01', end='1960-12-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test = pd.read_csv('flights_test.csv', parse_dates=True, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add predictions from both models\n",
    "\n",
    "flights_test['arima_predictions'] = model.predict(start='1960-01-01', end='1960-12-01').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(flights_test['passengers'], label='passenger_data')\n",
    "plt.plot(flights_test['arima_predictions'], label='arima predictions -- no seasnonality')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse_no_seasonality = np.sqrt(mean_squared_error(flights_test['passengers'], flights_test['arima_predictions']))\n",
    "\n",
    "test_rmse_no_seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### introducing SARIMAX to handle seasonailty and hopefully get a better model (measure by rmse on test data)\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the seasonal arima has 7 different hyperparameters: (p,d,q)(P,D,Q,m)\n",
    "# m here is the series period, which we know is 12\n",
    "# we can also use auto_arima to help us identify the best model\n",
    "\n",
    "\n",
    "auto_arima_model = auto_arima(flights_train['passengers'], start_p=0, start_q=0, max_p=10, max_q=10, max_d=2, \n",
    "                              seasonal=True, start_P=0, start_Q=0, max_D=2, m=12, max_P=10, max_Q=10,\n",
    "                              trace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_model = SARIMAX(flights_train['passengers'], \n",
    "                       order=(2,0,0), seasonal_order=(3,1,0,12)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate train error\n",
    "\n",
    "rmse_sarima = np.sqrt(mean_squared_error(flights_train['passengers'], \n",
    "                                         sarima_model.predict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_sarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(flights_train['passengers'], label='passenger_data')\n",
    "plt.plot(sarima_model.predict(), label='sarima predictions')\n",
    "plt.plot(model.predict(), label='arima predictions')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to compare correctly, drop the first period (12 months) of both predictions\n",
    "\n",
    "rmse_no_seasonality = np.sqrt(mean_squared_error(flights_train['passengers'].loc['1950':'1959'],\n",
    "                                                model.predict().loc['1950':'1959']))\n",
    "\n",
    "rmse_sarima = np.sqrt(mean_squared_error(flights_train['passengers'].loc['1950':'1959'],\n",
    "                                                sarima_model.predict().loc['1950':'1959']))\n",
    "\n",
    "print(rmse_no_seasonality, rmse_sarima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test['sarima_predictions'] = sarima_model.predict(start='1960-01-01', end='1960-12-01')\n",
    "\n",
    "plt.plot(flights_test['passengers'], label='passenger_data')\n",
    "plt.plot(flights_test['sarima_predictions'], label='sarima predictions')\n",
    "plt.plot(flights_test['arima_predictions'], label='arima predictions')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
