{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vjr_I3t51JmT"
   },
   "source": [
    "## Import libraries, set path and load the face detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2631,
     "status": "ok",
     "timestamp": 1669308171666,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "cykfVFM04VUg",
    "outputId": "f7ae7ad4-a029-4871-bb20-338571263111"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Connect with google drive\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1669308171667,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "oj-Y_gdv4JnO"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from string import digits\n",
    "import cv2\n",
    "import dlib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import ZeroPadding2D,Convolution2D,MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense,Dropout,Softmax,Flatten,Activation,BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1669308171667,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "WMIQGL3k4JnS",
    "outputId": "d9d2a95e-aa22-470a-f7a3-91e2580e3e76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.9.2\n",
      "Keras version: 2.9.0\n"
     ]
    }
   ],
   "source": [
    "# tensorflow & keras version\n",
    "print(f'TensorFlow version: {tf.__version__}')\n",
    "print(f'Keras version: {keras.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1669308171669,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "6TXWvxge5Hvg"
   },
   "outputs": [],
   "source": [
    "path = '/content/drive/MyDrive/spiced_projects/final_project/model_V3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1669308171670,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "pn0SDxP5DRAn"
   },
   "outputs": [],
   "source": [
    "# Download Dlib CNN face detector\n",
    "#!wget http://dlib.net/files/mmod_human_face_detector.dat.bz2\n",
    "#!bzip2 -dk mmod_human_face_detector.dat.bz2\n",
    "#%rm mmod_human_face_detector.dat.bz2\n",
    "\n",
    "# load the CNN face detector\n",
    "path_facedetector = path + 'mmod_human_face_detector.dat'\n",
    "dnnFaceDetector = dlib.cnn_face_detection_model_v1(path_facedetector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekBSNNXYlqJS"
   },
   "source": [
    "## Load the model and create folders for classification and blurred images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "executionInfo": {
     "elapsed": 1250,
     "status": "ok",
     "timestamp": 1669308174966,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "oFrM7SQao4dg"
   },
   "outputs": [],
   "source": [
    "classifier_model = tf.keras.models.load_model(path + 'saved_model/face_classifier_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "executionInfo": {
     "elapsed": 1613,
     "status": "ok",
     "timestamp": 1669308176569,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "bh7DyGD87Bh4"
   },
   "outputs": [],
   "source": [
    "vgg_face = tf.keras.models.load_model(path + 'saved_model/vgg_face.h5', compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1669308176570,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "kBZR4p50pFvp"
   },
   "outputs": [],
   "source": [
    "#class_rep = {1: 'adult', 0: 'toddler'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1669308176570,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "D04zKuGfpFdF"
   },
   "outputs": [],
   "source": [
    "# Path to folder which contains images to be tested and predicted\n",
    "#test_images_path = path + 'test_images_unknown/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1669308176571,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "hCi4A4gSpFyg",
    "outputId": "019dd00a-cb62-41ef-c950-f90d75273d50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory /content/drive/MyDrive/spiced_projects/final_project/model_V3/data/Classification was already created!\n"
     ]
    }
   ],
   "source": [
    "isExist = os.path.exists(path + 'data/Classification')\n",
    "if not isExist:\n",
    "   os.mkdir(path + 'data/Classification')\n",
    "   print(\"The new directory  \" + path + 'data/Classification' + \"  is created!\")\n",
    "else:\n",
    "  print(\"The directory \" + path + 'data/Classification' + \" was already created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1669308176571,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "LicOyufdSrNd",
    "outputId": "6e17811d-04a7-4df9-c819-57c5c58552c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory /content/drive/MyDrive/spiced_projects/final_project/model_V3/data/Blur was already created!\n"
     ]
    }
   ],
   "source": [
    "isExist = os.path.exists(path + 'data/Blur')\n",
    "if not isExist:\n",
    "   os.mkdir(path + 'data/Blur')\n",
    "   print(\"The new directory  \" + path + 'data/Blur' + \"  is created!\")\n",
    "else:\n",
    "  print(\"The directory \" + path + 'data/Blur' + \" was already created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SP5VIrfoCy_f"
   },
   "source": [
    "## Classification time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1669308179096,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "9LsafAkPpFsc"
   },
   "outputs": [],
   "source": [
    "def plot_predictions(img):\n",
    "  plt.figure(figsize=(8,4))\n",
    "  plt.imshow(img[:,:,::-1])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1669308182317,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "RcZVpuE6pF1J"
   },
   "outputs": [],
   "source": [
    "def image_classification(file_path = os.listdir(path + 'data/test_images_unknown/')):      \n",
    "  for img_name in file_path:\n",
    "    if img_name == 'crop_img.jpg':\n",
    "      continue\n",
    "    # Load Image\n",
    "    img = cv2.imread(path + 'data/test_images_unknown/' + img_name)\n",
    "\n",
    "    print(path + 'data/test_images_unknown/' + img_name)\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    rects = dnnFaceDetector(gray,1)\n",
    "    left,top,right,bottom = 0,0,0,0\n",
    "    for (i,rect) in enumerate(rects):\n",
    "      left   = rect.rect.left()   #x1\n",
    "      top    = rect.rect.top()    #y1\n",
    "      right  = rect.rect.right()  #x2\n",
    "      bottom = rect.rect.bottom() #y2\n",
    "      width  = right-left\n",
    "      height = bottom-top\n",
    "      img_crop = img[top:top+height,left:left+width]\n",
    "      cv2.imwrite(path + 'data/test_images_unknown/crop_img.jpg',img_crop)\n",
    "      \n",
    "      # Get Embeddings\n",
    "      crop_img = load_img(path + 'data/test_images_unknown/crop_img.jpg',target_size = (224,224))\n",
    "      crop_img = img_to_array(crop_img)\n",
    "      crop_img = np.expand_dims(crop_img,axis=0)\n",
    "      crop_img = preprocess_input(crop_img)\n",
    "      img_encode = vgg_face(crop_img)\n",
    "\n",
    "      # Make Predictions\n",
    "      embed = K.eval(img_encode)\n",
    "      person = classifier_model.predict(embed)     \n",
    "      if person[0] <= 0.5:\n",
    "        name = 'child'\n",
    "        person[0] = 1 - person[0]\n",
    "      else:\n",
    "        name = 'adult' \n",
    "        #name = 'spicy tutor' \n",
    "        person[0] = person[0]\n",
    "      os.remove(path + 'data/test_images_unknown/crop_img.jpg')\n",
    "      cv2.rectangle(img,(left,top),(right,bottom),(0,255,0), 2)\n",
    "      img = cv2.putText(img,name,(left,top-10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,255),2,cv2.LINE_AA)\n",
    "      img = cv2.putText(img,str(np.max(person)),(right,bottom+10),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255),1,cv2.LINE_AA)\n",
    "\n",
    "    # Save images with bounding box,name and accuracy \n",
    "    cv2.imwrite(path + 'data/Classification/' + img_name,img)\n",
    "    print(path + 'data/Classification/' + img_name)\n",
    "    plot_predictions(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classification()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5LtxSr7EyLJ"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Blur time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "executionInfo": {
     "elapsed": 821,
     "status": "ok",
     "timestamp": 1669308203793,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "uFWY_4f-LLDL"
   },
   "outputs": [],
   "source": [
    "def image_blur(file_path = os.listdir(path + 'data/test_images_unknown/')):      \n",
    "  for img_name in file_path:\n",
    "    if img_name == 'crop_img.jpg':\n",
    "      continue\n",
    "    # Load Image\n",
    "    img = cv2.imread(path + 'data/test_images_unknown/' + img_name)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect Faces\n",
    "    rects = dnnFaceDetector(gray,1)\n",
    "    left,top,right,bottom = 0,0,0,0\n",
    "    for (i,rect) in enumerate(rects):\n",
    "      # Extract Each Face\n",
    "      left   = rect.rect.left()   #x1\n",
    "      top    = rect.rect.top()    #y1\n",
    "      right  = rect.rect.right()  #x2\n",
    "      bottom = rect.rect.bottom() #y2\n",
    "      width  = right-left\n",
    "      height = bottom-top\n",
    "      img_crop = img[top:top+height,left:left+width]\n",
    "      cv2.imwrite(path + 'data/test_images_unknown/crop_img.jpg',img_crop)\n",
    "      \n",
    "      # Get Embeddings\n",
    "      crop_img = load_img(path + 'data/test_images_unknown/crop_img.jpg',target_size=(224,224))\n",
    "      crop_img = img_to_array(crop_img)\n",
    "      crop_img = np.expand_dims(crop_img,axis=0)\n",
    "      crop_img = preprocess_input(crop_img)\n",
    "      img_encode = vgg_face(crop_img)\n",
    "\n",
    "      # Make Predictions\n",
    "      embed = K.eval(img_encode)\n",
    "      person = classifier_model.predict(embed)\n",
    "      if person[0] <= 0.5:\n",
    "        name = 'child'\n",
    "      else:\n",
    "        name = 'adult' \n",
    "      os.remove(path + 'data/test_images_unknown/crop_img.jpg')\n",
    "\n",
    "      if name == 'child':\n",
    "        blurred_part = cv2.blur(img[top:top+height,left:left+width], ksize=(20, 20), )\n",
    "        img[top:top+height,left:left+width] = blurred_part\n",
    "      else:\n",
    "        img\n",
    "\n",
    "    # Save images with bounding box,name and accuracy  \n",
    "    cv2.imwrite(path + 'data/Blur/' + img_name,img)\n",
    "    plot_predictions(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_blur()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "executionInfo": {
     "elapsed": 860,
     "status": "ok",
     "timestamp": 1669308498104,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "O7TOrjY9bkNg"
   },
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/drive/1QnC7lV7oVFk5OZCm75fqbLAfD9qBy9bw?usp=sharing#scrollTo=09b_0FAnUa9y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1669308498584,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "utXysfTSYSkF"
   },
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from IPython.display import display, Javascript, Image\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode, b64encode\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n",
    "import io\n",
    "import html\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1669308498584,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "njd5NKF7bhbw"
   },
   "outputs": [],
   "source": [
    "# function to convert the JavaScript object into an OpenCV image\n",
    "def js_to_image(js_reply):\n",
    "  \"\"\"\n",
    "  Params:\n",
    "          js_reply: JavaScript object containing image from webcam\n",
    "  Returns:\n",
    "          img: OpenCV BGR image\n",
    "  \"\"\"\n",
    "  # decode base64 image\n",
    "  image_bytes = b64decode(js_reply.split(',')[1])\n",
    "  # convert bytes to numpy array\n",
    "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
    "  # decode numpy array into OpenCV BGR image\n",
    "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
    "\n",
    "  return img\n",
    "\n",
    "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
    "def bbox_to_bytes(bbox_array):\n",
    "  \"\"\"\n",
    "  Params:\n",
    "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
    "  Returns:\n",
    "        bytes: Base64 image byte string\n",
    "  \"\"\"\n",
    "  # convert array into PIL image\n",
    "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
    "  iobuf = io.BytesIO()\n",
    "  # format bbox into png for return\n",
    "  bbox_PIL.save(iobuf, format='png')\n",
    "  # format return string\n",
    "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
    "\n",
    "  return bbox_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1669308498585,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "nmVz10S6sIVt",
    "outputId": "343f63ad-6a1a-4bf2-8968-453b482ae03a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory /content/drive/MyDrive/spiced_projects/final_project/model_V3/data/Garlics was already created!\n"
     ]
    }
   ],
   "source": [
    "isExist = os.path.exists(path + 'data/Garlics')\n",
    "if not isExist:\n",
    "   os.mkdir(path + 'data/Garlics')\n",
    "   print(\"The new directory  \" + path + 'data/Garlics' + \"  is created!\")\n",
    "else:\n",
    "  print(\"The directory \" + path + 'data/Garlics' + \" was already created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1669308498585,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "pLeU30hjbLkS"
   },
   "outputs": [],
   "source": [
    "# initialize the Haar Cascade face detection model\n",
    "face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1669308498586,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "xqMhZxsVonhN"
   },
   "outputs": [],
   "source": [
    "def take_photo(filename='photo.jpg', quality=0.8):\n",
    "  js = Javascript('''\n",
    "    async function takePhoto(quality) {\n",
    "      const div = document.createElement('div');\n",
    "      const capture = document.createElement('button');\n",
    "      capture.textContent = 'Capture';\n",
    "      div.appendChild(capture);\n",
    "\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "      document.body.appendChild(div);\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      // Resize the output to fit the video element.\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "      // Wait for Capture to be clicked.\n",
    "      await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "      const canvas = document.createElement('canvas');\n",
    "      canvas.width = video.videoWidth;\n",
    "      canvas.height = video.videoHeight;\n",
    "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "      stream.getVideoTracks()[0].stop();\n",
    "      div.remove();\n",
    "      return canvas.toDataURL('image/jpeg', quality);\n",
    "    }\n",
    "    ''')\n",
    "  display(js)\n",
    "\n",
    "  # get photo data\n",
    "  data = eval_js('takePhoto({})'.format(quality))\n",
    "  # get OpenCV format image\n",
    "  img = js_to_image(data) \n",
    "  # grayscale img\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "  #print(gray.shape)\n",
    "  # get face bounding box coordinates using Haar Cascade\n",
    "\n",
    "  #     faces = face_cascade.detectMultiScale(gray)\n",
    "  \n",
    "  # draw face bounding box on image\n",
    "  #      for (x,y,w,h) in faces:\n",
    "  #             img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "  # save image\n",
    "  cv2.imwrite(filename, img)\n",
    "\n",
    "  return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1669308498587,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "ejGp8FultnRV"
   },
   "outputs": [],
   "source": [
    "def plot_predictions(img):\n",
    "  plt.figure(figsize=(8,4))\n",
    "  plt.imshow(img[:,:,::-1])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1669308498588,
     "user": {
      "displayName": "Florian Riemann",
      "userId": "03933270795632311440"
     },
     "user_tz": -60
    },
    "id": "Wx_N_mEptoEk"
   },
   "outputs": [],
   "source": [
    "def gb_classification(file_path = os.listdir(path + 'data/Garlics/')):      \n",
    "  for img_name in file_path:\n",
    "    if img_name == 'crop_img.jpg':\n",
    "      continue\n",
    "    # Load Image\n",
    "    img = cv2.imread(path + 'data/Garlics/' + img_name)\n",
    "\n",
    "    print(path + 'data/Garlics/' + img_name)\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    rects = dnnFaceDetector(gray,1)\n",
    "    left,top,right,bottom = 0,0,0,0\n",
    "    for (i,rect) in enumerate(rects):\n",
    "      left   = rect.rect.left()   #x1\n",
    "      top    = rect.rect.top()    #y1\n",
    "      right  = rect.rect.right()  #x2\n",
    "      bottom = rect.rect.bottom() #y2\n",
    "      width  = right-left\n",
    "      height = bottom-top\n",
    "      img_crop = img[top:top+height,left:left+width]\n",
    "      cv2.imwrite(path + 'data/Garlics/crop_img.jpg',img_crop)\n",
    "      \n",
    "      # Get Embeddings\n",
    "      crop_img = load_img(path + 'data/Garlics/crop_img.jpg',target_size = (224,224))\n",
    "      crop_img = img_to_array(crop_img)\n",
    "      crop_img = np.expand_dims(crop_img,axis=0)\n",
    "      crop_img = preprocess_input(crop_img)\n",
    "      img_encode = vgg_face(crop_img)\n",
    "\n",
    "      # Make Predictions\n",
    "      embed = K.eval(img_encode)\n",
    "      person = classifier_model.predict(embed)     \n",
    "      if person[0] <= 2.0:\n",
    "        name = '100% Garlic Booster'\n",
    "      else:\n",
    "        name = '' \n",
    "      os.remove(path + 'data/Garlics/crop_img.jpg')\n",
    "      cv2.rectangle(img,(left,top),(right,bottom),(0,255,0), 1)\n",
    "      img = cv2.putText(img,name,(left,top-10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,255),1,cv2.LINE_AA)\n",
    "      #img = cv2.putText(img),(right,bottom+10),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255),1,cv2.LINE_AA)\n",
    "\n",
    "    # Save images with bounding box,name and accuracy \n",
    "    cv2.imwrite(path + 'data/Garlics/' + img_name,img)\n",
    "    print(path + 'data/Garlics/' + img_name)\n",
    "    plot_predictions(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ab6XFWUSsksX"
   },
   "source": [
    "## Take picture of Garlic Boosters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  filename = take_photo(path + 'data/Garlics/garlicbooster.jpeg')\n",
    "  print('Saved to {}'.format(filename))\n",
    "  \n",
    "  # Show the image which was just taken.\n",
    "  display(Image(filename))\n",
    "except Exception as err:\n",
    "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
    "  # grant the page permission to access it.\n",
    "  print(str(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3wH2eA2tW74"
   },
   "source": [
    "### Classification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_classification()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Vjr_I3t51JmT",
    "ekBSNNXYlqJS",
    "m5LtxSr7EyLJ",
    "R4vl8up1YJ2m"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
